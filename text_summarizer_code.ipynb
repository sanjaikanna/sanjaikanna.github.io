{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzg5pfCTNSJR1GQw4+Asqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjaikanna/sanjaikanna.github.io/blob/main/text_summarizer_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from google.colab import files\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class TextSummarizer:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.punctuation = set(string.punctuation)\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        \"\"\"Custom text processing pipeline\"\"\"\n",
        "        # Store original sentences\n",
        "        self.original_sentences = sent_tokenize(text)\n",
        "\n",
        "        # Word-level preprocessing\n",
        "        processed_sentences = []\n",
        "        for sent in self.original_sentences:\n",
        "            words = nltk.word_tokenize(sent.lower())\n",
        "            words = [w for w in words if w not in self.stop_words and w not in self.punctuation]\n",
        "            processed_sentences.append(' '.join(words))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def train_model(self, processed_sentences):\n",
        "        \"\"\"Train TF-IDF model on the processed text\"\"\"\n",
        "        return self.vectorizer.fit_transform(processed_sentences)\n",
        "\n",
        "    def generate_summary(self, text, num_sentences=3):\n",
        "        \"\"\"End-to-end summarization with custom trained model\"\"\"\n",
        "        processed_sentences = self.preprocess(text)\n",
        "        X = self.train_model(processed_sentences)\n",
        "\n",
        "        # Convert to array and calculate scores\n",
        "        sentence_scores = np.array(X.sum(axis=1)).flatten()\n",
        "        top_sentence_indices = np.argsort(-sentence_scores)[:num_sentences]\n",
        "        top_sentence_indices.sort()  # Maintain original order\n",
        "\n",
        "        return ' '.join([self.original_sentences[i] for i in top_sentence_indices])\n",
        "\n",
        "def main():\n",
        "    print(\"ðŸ§  AI-Powered Text Summarizer (Custom Implementation)\")\n",
        "    print(\"1. Paste text\\n2. Upload file\\n\")\n",
        "\n",
        "    choice = input(\"Choose input method (1/2): \").strip()\n",
        "    text = \"\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(\"\\nPaste your text (press Enter twice to finish):\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if not line and lines:\n",
        "                break\n",
        "            lines.append(line)\n",
        "        text = \"\\n\".join(lines)\n",
        "    elif choice == \"2\":\n",
        "        print(\"\\nUpload text file:\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            text = next(iter(uploaded.values())).decode('utf-8')\n",
        "\n",
        "    if not text.strip():\n",
        "        print(\"Error: No text provided!\")\n",
        "        return\n",
        "\n",
        "    # Initialize and use our custom summarizer\n",
        "    summarizer = TextSummarizer()\n",
        "    summary = summarizer.generate_summary(text)\n",
        "\n",
        "    print(\"\\n=== ORIGINAL TEXT ===\")\n",
        "    print(text[:500] + (\"...\" if len(text) > 500 else \"\"))\n",
        "    print(\"\\n=== AI-GENERATED SUMMARY ===\")\n",
        "    print(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KX6mmr1Zyuq",
        "outputId": "59a95d00-3d79-4f43-9563-76f4c4951dc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  AI-Powered Text Summarizer (Custom Implementation)\n",
            "1. Paste text\n",
            "2. Upload file\n",
            "\n",
            "Choose input method (1/2): 1\n",
            "\n",
            "Paste your text (press Enter twice to finish):\n",
            "The most notable thing about Time is that it is so purely relative. A large amount of reminiscence is, by common consent, conceded to the drowning man; and it is not past belief that one may review an entire courtship while removing one's gloves. That is what Trysdale was doing, standing by a table in his bachelor apartments. On the table stood a singular-looking green plant in a red earthen jar. The plant was one of the species of cacti, and was provided with long, tentacular leaves that perpetually swayed with the slightest breeze with a peculiar creeping motion almost sentient\n",
            "\n",
            "\n",
            "=== ORIGINAL TEXT ===\n",
            "The most notable thing about Time is that it is so purely relative. A large amount of reminiscence is, by common consent, conceded to the drowning man; and it is not past belief that one may review an entire courtship while removing one's gloves. That is what Trysdale was doing, standing by a table in his bachelor apartments. On the table stood a singular-looking green plant in a red earthen jar. The plant was one of the species of cacti, and was provided with long, tentacular leaves that perpet...\n",
            "\n",
            "=== AI-GENERATED SUMMARY ===\n",
            "A large amount of reminiscence is, by common consent, conceded to the drowning man; and it is not past belief that one may review an entire courtship while removing one's gloves. On the table stood a singular-looking green plant in a red earthen jar. The plant was one of the species of cacti, and was provided with long, tentacular leaves that perpetually swayed with the slightest breeze with a peculiar creeping motion almost sentient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GHkVQ1viMv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "sluX-CedqsZN"
      }
    }
  ]
}